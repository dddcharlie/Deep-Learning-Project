{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features is: (42000, 784)\n",
      "the shape of labels is: (42000,)\n",
      "the range of features is: 0 to 255\n",
      "the range of labels is: 0 to 9\n",
      "label 1 is 1\n",
      "label 2 is 0\n",
      "label 3 is 1\n",
      "label 4 is 4\n",
      "label 5 is 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               77056     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 346,742\n",
      "Trainable params: 346,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 0.4192 - acc: 0.8708 - val_loss: 0.2996 - val_acc: 0.9027\n",
      "Epoch 2/300\n",
      " - 1s - loss: 0.1491 - acc: 0.9546 - val_loss: 0.1420 - val_acc: 0.9592\n",
      "Epoch 3/300\n",
      " - 1s - loss: 0.0974 - acc: 0.9701 - val_loss: 0.1200 - val_acc: 0.9656\n",
      "Epoch 4/300\n",
      " - 1s - loss: 0.0653 - acc: 0.9790 - val_loss: 0.1163 - val_acc: 0.9681\n",
      "Epoch 5/300\n",
      " - 1s - loss: 0.0485 - acc: 0.9845 - val_loss: 0.1211 - val_acc: 0.9677\n",
      "Epoch 6/300\n",
      " - 1s - loss: 0.0334 - acc: 0.9890 - val_loss: 0.1411 - val_acc: 0.9644\n",
      "Epoch 7/300\n",
      " - 1s - loss: 0.0276 - acc: 0.9907 - val_loss: 0.1405 - val_acc: 0.9632\n",
      "Epoch 8/300\n",
      " - 1s - loss: 0.0210 - acc: 0.9935 - val_loss: 0.1284 - val_acc: 0.9705\n",
      "Epoch 9/300\n",
      " - 1s - loss: 0.0169 - acc: 0.9944 - val_loss: 0.1342 - val_acc: 0.9707\n",
      "Epoch 10/300\n",
      " - 1s - loss: 0.0134 - acc: 0.9956 - val_loss: 0.1240 - val_acc: 0.9743\n",
      "Epoch 11/300\n",
      " - 1s - loss: 0.0108 - acc: 0.9960 - val_loss: 0.1525 - val_acc: 0.9706\n",
      "Epoch 12/300\n",
      " - 1s - loss: 0.0102 - acc: 0.9968 - val_loss: 0.1761 - val_acc: 0.9692\n",
      "Epoch 13/300\n",
      " - 1s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.1512 - val_acc: 0.9736\n",
      "Epoch 14/300\n",
      " - 1s - loss: 0.0100 - acc: 0.9972 - val_loss: 0.1594 - val_acc: 0.9717\n",
      "Epoch 15/300\n",
      " - 1s - loss: 0.0082 - acc: 0.9973 - val_loss: 0.1604 - val_acc: 0.9725\n",
      "Epoch 16/300\n",
      " - 1s - loss: 0.0065 - acc: 0.9979 - val_loss: 0.1882 - val_acc: 0.9693\n",
      "Epoch 17/300\n",
      " - 2s - loss: 0.0055 - acc: 0.9982 - val_loss: 0.1674 - val_acc: 0.9735\n",
      "Epoch 18/300\n",
      " - 1s - loss: 0.0051 - acc: 0.9984 - val_loss: 0.1745 - val_acc: 0.9740\n",
      "Epoch 19/300\n",
      " - 1s - loss: 0.0061 - acc: 0.9982 - val_loss: 0.1813 - val_acc: 0.9737\n",
      "Epoch 20/300\n",
      " - 1s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1726 - val_acc: 0.9756\n",
      "Epoch 21/300\n",
      " - 1s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.1685 - val_acc: 0.9762\n",
      "Epoch 22/300\n",
      " - 1s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.1719 - val_acc: 0.9764\n",
      "Epoch 23/300\n",
      " - 1s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.1817 - val_acc: 0.9758\n",
      "Epoch 24/300\n",
      " - 1s - loss: 0.0039 - acc: 0.9987 - val_loss: 0.2053 - val_acc: 0.9740\n",
      "Epoch 25/300\n",
      " - 1s - loss: 0.0046 - acc: 0.9987 - val_loss: 0.1851 - val_acc: 0.9749\n",
      "Epoch 26/300\n",
      " - 1s - loss: 0.0035 - acc: 0.9988 - val_loss: 0.2165 - val_acc: 0.9731\n",
      "Epoch 27/300\n",
      " - 1s - loss: 0.0037 - acc: 0.9990 - val_loss: 0.2359 - val_acc: 0.9733\n",
      "Epoch 28/300\n",
      " - 2s - loss: 0.0042 - acc: 0.9989 - val_loss: 0.2283 - val_acc: 0.9719\n",
      "Epoch 29/300\n",
      " - 2s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.2199 - val_acc: 0.9733\n",
      "Epoch 30/300\n",
      " - 1s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.1872 - val_acc: 0.9756\n",
      "Epoch 31/300\n",
      " - 1s - loss: 0.0046 - acc: 0.9990 - val_loss: 0.2382 - val_acc: 0.9738\n",
      "Epoch 32/300\n",
      " - 1s - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1736 - val_acc: 0.9777\n",
      "Epoch 33/300\n",
      " - 1s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.2113 - val_acc: 0.9746\n",
      "Epoch 34/300\n",
      " - 1s - loss: 0.0019 - acc: 0.9994 - val_loss: 0.2065 - val_acc: 0.9758\n",
      "Epoch 35/300\n",
      " - 1s - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2061 - val_acc: 0.9769\n",
      "Epoch 36/300\n",
      " - 1s - loss: 0.0033 - acc: 0.9993 - val_loss: 0.2066 - val_acc: 0.9763\n",
      "Epoch 37/300\n",
      " - 1s - loss: 0.0022 - acc: 0.9993 - val_loss: 0.2221 - val_acc: 0.9748\n",
      "Epoch 38/300\n",
      " - 1s - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1989 - val_acc: 0.9771\n",
      "Epoch 39/300\n",
      " - 1s - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2133 - val_acc: 0.9757\n",
      "Epoch 40/300\n",
      " - 1s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2189 - val_acc: 0.9767\n",
      "Epoch 41/300\n",
      " - 1s - loss: 0.0017 - acc: 0.9997 - val_loss: 0.2392 - val_acc: 0.9732\n",
      "Epoch 42/300\n",
      " - 1s - loss: 0.0047 - acc: 0.9989 - val_loss: 0.2197 - val_acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d83b87b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function               # Allows for python3 printing\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential                 # import the sequential model, which is a core object in Keras\n",
    "from keras.layers import Dense, Activation          # import the dense layer, AKA the fully connected layer\n",
    "                                                    # and Keras' library of activation functions\n",
    "from keras.optimizers import SGD                    #  import SGD as optimizer\n",
    "\n",
    "import pandas                                       # Data storage\n",
    "from sklearn.model_selection import train_test_split# Splits dataset\n",
    "\n",
    "dataset = pandas.read_csv(\"train.csv\") # Read in data\n",
    "dataset = dataset.as_matrix() # Convert to ndarray\n",
    "X,y = dataset[:,1:], dataset[:,0] # Separate data points and labels\n",
    "\n",
    "\n",
    "print ('the shape of features is:',X.shape)       #print data shape\n",
    "print ('the shape of labels is:',y.shape)       #print data shape\n",
    "\n",
    "import numpy as np\n",
    "print ('the range of features is:',np.min(X),'to',np.max(X))\n",
    "print ('the range of labels is:',np.min(y),'to',np.max(y))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(5):\n",
    "    image = X[i]\n",
    "    plt.subplot(1,10, i+1)\n",
    "    image = image.reshape(28,28)\n",
    "    print ('label', i+1, 'is',y[i])\n",
    "    plt.imshow(image, cmap='Greys')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "# The training and testing data are 28 by 28 images, and thus the total number of features is 28 x 28 = 784.\n",
    "# \n",
    "# ## 4. Prepare the data\n",
    "# Here we need to divide it by 255 for normalization, since the features are pixels value from 0 to 255. After that, we will use function from keras **utils.to.categoriacal** to do one-hot encoding. \n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.20) # Split data\n",
    "\n",
    "x_train = x_train/255.0                           # normalize training data\n",
    "x_val = x_val/255.0                             # normalize testing data\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=10)\n",
    "\n",
    "\n",
    "# ## 5.1 Create the model\n",
    "# We want to set several parameters at the beginning so that we can easily see them and change them. It would also be clear to others when reading your code and try to see what parameter you used. Here the most important parameters to set are training epochs, batch size, and learning rate. \n",
    "# \n",
    "# Batch size refers to the portion of the entire sample that you want to put into the neural network for training. One epoch is when all samples are trained once. Learning rate is how fast you want the model to train, but large learning rates would likely to cause problems such as missing the optimal solution (overshoot).\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# set parameters\n",
    "batch_size = 256\n",
    "epochs = 300\n",
    "learning_rate = 0.001\n",
    "\n",
    "# build the model\n",
    "model = Sequential()                                         # define model to be sequential\n",
    "model.add(Dense(300, activation='relu',input_dim=784))       # first hidden layer with 256 neurons\n",
    "model.add(Dense(256, activation='relu'))                     # second hidden layer with 256 neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))                   # output layer\n",
    "model.summary()                                              # print out summary for all layers \n",
    "\n",
    "\n",
    "my_optimizer = keras.optimizers.RMSprop(lr=learning_rate)                   # using learning rate 0.001\n",
    "model.compile(optimizer=my_optimizer,                        # using SGD with our set lr as optimizer\n",
    "              loss='categorical_crossentropy',               # using cross entropy loss\n",
    "              metrics=['accuracy'])                          # metric that is called during evaluation\n",
    "\n",
    "\n",
    "best_weights_filepath = './best_weights.hdf5' ##define the filename to store\n",
    "                                            ##the best performance and weights\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                              patience = 10) \n",
    "#Stop training early if val_acc doesn't improve for 5 epochs\n",
    "\n",
    "SaveBestWeights = keras.callbacks.ModelCheckpoint(best_weights_filepath,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True)\n",
    "# store the historically best performing weights in best_weights_filepath\n",
    "#, where performance is given by accuracy on the validation set.\n",
    "\n",
    "\n",
    "model_history = model.fit(x_train, y_train,                   # training data \n",
    "                    batch_size=batch_size,                   # batch size 256\n",
    "                    epochs=epochs,                           # 15 epochs \n",
    "                    verbose= 2,                              # verbose level\n",
    "                    validation_data = (x_val, y_val),  #Use the previously defined x_test as a validation set. \n",
    "                    callbacks = [earlyStopping, SaveBestWeights]\n",
    "                         )     \n",
    "model.load_weights(best_weights_filepath) ##Set the best performing weights to the model\n",
    "\n",
    "\n",
    "# ## 6. Evaluate the model:Submission to Kaggle\n",
    "# We first need to read in the data and then convert it into a numpy array so we can perform numpy operations on it. Next, we will make predictions for the Kaggle test set. We cannot evaluate our performance on this test set, as Kaggle keeps these a secret so that we can't cheat. (Cheating is actually really easy, but they're really good at telling when it happens)\n",
    "# \n",
    "# To be clear, we defined an evaluation set above\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "testset = pandas.read_csv(\"test.csv\")             # Read data\n",
    "testset = testset.as_matrix()                     # Convert to ndarray\n",
    "testset = testset/255.0                             # normalize testing data\n",
    "predictions = model.predict_classes(testset)           # Predict\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "submission = pandas.DataFrame(data=predictions, index=np.arange(1,len(predictions)+1), columns=['Label']) # Create dataframe\n",
    "submission.index.name = 'ImageId' # Set index name\n",
    "\n",
    "csv_text = submission.to_csv() # Convert to text\n",
    "\n",
    "# Write to file 'submission.csv'\n",
    "with open(\"submission.csv\",'w') as csv_file:\n",
    "    csv_file.write(csv_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
